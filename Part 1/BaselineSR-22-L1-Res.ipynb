{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import sklearn.feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from fastai.layers import PixelShuffle_ICNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/workspace/data/Dhruv/pytorch/SuperResolution/Data'\n",
    "writer = SummaryWriter('runs/2_2_L1_Res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros((800, 2048, 1080, 3))\n",
    "i = 0\n",
    "for f in os.listdir(dir + '/' + 'Train'):\n",
    "    if(f.endswith(\".png\")):\n",
    "        train_images[i] = (skimage.transform.resize(\n",
    "            skimage.io.imread(dir + '/Train/' + f),(2048,1080), mode ='constant'))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract 64x64 patches from the images. 20 patches from each image.\n",
    "def patchExtract(images, patch_size=(224, 224), max_patches=5):\n",
    "    pe = sklearn.feature_extraction.image.PatchExtractor(patch_size=patch_size, max_patches = max_patches)\n",
    "    pe_fit = pe.fit(images)\n",
    "    pe_trans = pe.transform(images)\n",
    "    return pe_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = patchExtract(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.zeros((100, 2048, 1080, 3))\n",
    "i = 0\n",
    "for f in os.listdir(dir + '/' + 'Validation'):\n",
    "    if(f.endswith(\".png\")):\n",
    "        test_images[i] = (skimage.transform.resize(\n",
    "            skimage.io.imread(dir + '/Validation/' + f),(2048,1080), mode ='constant'))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_images1 = np.asarray(train_images[:400], dtype=np.float32)\n",
    "train_images_patches1 = patchExtract(train_images1)\n",
    "del train_images1\n",
    "\n",
    "test_images = np.asarray(test_images, dtype=np.float32)\n",
    "test_images_patches = patchExtract(test_images)\n",
    "\n",
    "train_images1 = np.asarray(train_images[400:], dtype=np.float32)\n",
    "train_images_patches2 = patchExtract(train_images1)\n",
    "train_images_patches = np.concatenate((train_images_patches1, train_images_patches2), axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = patchExtract(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicubicDownsample(images, scale_factor=0.5):\n",
    "    out = torch.nn.functional.interpolate(images, scale_factor=scale_factor, mode='bicubic', align_corners=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = torch.from_numpy(train_images).permute(0,3,1,2)\n",
    "y_tr = y_tr.float()\n",
    "y_te = torch.from_numpy(test_images).permute(0,3,1,2)\n",
    "y_te = y_te.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_images\n",
    "del test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = bicubicDownsample(y_tr)\n",
    "x_tr = x_tr.float()\n",
    "x_te = bicubicDownsample(y_te)\n",
    "x_te = x_te.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = y_tr.contiguous()\n",
    "y_te = y_te.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_tr.is_contiguous())\n",
    "print(x_te.is_contiguous())\n",
    "print(y_tr.is_contiguous())\n",
    "print(y_te.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom training dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = x_tr\n",
    "        self.y = y_tr\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "# Creating custom testing dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = x_te\n",
    "        self.y = y_te\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset()\n",
    "test_dataset = TestDataset()\n",
    "\n",
    "# Implementing train loader to split the data into batches\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, # data reshuffled at every epoch\n",
    "                          num_workers=2) # Use several subprocesses to load the data\n",
    "\n",
    "# Implementing train loader to split the data into batches\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, # data reshuffled at every epoch\n",
    "                          num_workers=2) # Use several subprocesses to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "n_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(n_samples/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, kernel_size = 1) # Skip connection\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_x = self.skip(x)\n",
    "        conv_x = self.double_conv(x)\n",
    "        added_x = skip_x + conv_x  # Element-wise addition of skip connection filters and residual filters\n",
    "        return F.relu_(added_x) # Inplace functional version of relu\n",
    "    \n",
    "\n",
    "class PsUpsample(nn.Module): # Upsampling using pixel shuffle\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = PixelShuffle_ICNR(in_channels, in_channels//2) # Reduction of C by 2^2\n",
    "        self.dconv = DoubleConv(in_channels, in_channels//2)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        x = torch.cat((x2, x1), dim=1)\n",
    "        x = self.dconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = torchvision.models.resnet34(pretrained=True, progress=False) # Pretrained Resnet34 for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.model import DynamicUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = DynamicUnet(resnet_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder path\n",
    "        '''\n",
    "        self.in_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        '''\n",
    "        self.in_conv = nn.Sequential(\n",
    "            resnet_model.conv1,\n",
    "            resnet_model.bn1,\n",
    "            resnet_model.relu,\n",
    "            resnet_model.maxpool\n",
    "        )\n",
    "        \n",
    "        self.layer1_0 = resnet_model.layer1[0]\n",
    "        self.layer1_1 = resnet_model.layer1[1]\n",
    "        self.layer1_2 = resnet_model.layer1[2]\n",
    "        \n",
    "        self.layer2_0 = nn.Sequential(\n",
    "            resnet_model.layer2[0].conv1,\n",
    "            resnet_model.layer2[0].bn1,\n",
    "            resnet_model.layer2[0].relu,\n",
    "            resnet_model.layer2[0].conv2,\n",
    "            resnet_model.layer2[0].bn2\n",
    "        )\n",
    "        self.layer2_1 = resnet_model.layer2[1]\n",
    "        self.layer2_2 = resnet_model.layer2[2]\n",
    "        self.layer2_3 = resnet_model.layer2[3]\n",
    "        \n",
    "        self.il2 = resnet_model.layer2[0].downsample\n",
    "        \n",
    "        self.layer3_0 = nn.Sequential(\n",
    "            resnet_model.layer3[0].conv1,\n",
    "            resnet_model.layer3[0].bn1,\n",
    "            resnet_model.layer3[0].relu,\n",
    "            resnet_model.layer3[0].conv2,\n",
    "            resnet_model.layer3[0].bn2\n",
    "        )\n",
    "        self.layer3_1 = resnet_model.layer3[1]\n",
    "        self.layer3_2 = resnet_model.layer3[2]\n",
    "        self.layer3_3 = resnet_model.layer3[3]\n",
    "        self.layer3_4 = resnet_model.layer3[4]\n",
    "        self.layer3_5 = resnet_model.layer3[5]\n",
    "        \n",
    "        self.il3 = resnet_model.layer3[0].downsample\n",
    "        \n",
    "        self.layer4_0 = nn.Sequential(\n",
    "            resnet_model.layer4[0].conv1,\n",
    "            resnet_model.layer4[0].bn1,\n",
    "            resnet_model.layer4[0].relu,\n",
    "            resnet_model.layer4[0].conv2,\n",
    "            resnet_model.layer4[0].bn2\n",
    "        )\n",
    "        self.layer4_1 = resnet_model.layer4[1]\n",
    "        self.layer4_2 = resnet_model.layer4[2]\n",
    "        \n",
    "        self.il4 = resnet_model.layer4[0].downsample\n",
    "        \n",
    "        # Decoder path\n",
    "        self.up1 = PsUpsample(512) # Reduction of C by 2^2 followed by 1x1 conv, concat and DoubleConv i.e. output channels = 512\n",
    "        self.up2 = PsUpsample(256)\n",
    "        self.up3 = PsUpsample(128)\n",
    "        self.outconvblock = nn.Sequential(                   # Input to this block has 128 channels and image size = input size\n",
    "            PixelShuffle_ICNR(64, 64),          # This block is like the one in SRGAN    # This block can be repeated for x4\n",
    "            nn.ReLU(inplace=True),                # Remove this ReLU?\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            PixelShuffle_ICNR(64, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.outconv = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=7, padding=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "             \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Encoder Path\n",
    "        x = self.in_conv(x)\n",
    "        \n",
    "        # Layer 1\n",
    "        identity = x\n",
    "        x = self.layer1_0(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer1_1(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer1_2(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x1 = x\n",
    "        \n",
    "        # Layer 2\n",
    "        identity = x\n",
    "        x = self.layer2_0(x)\n",
    "        identity = self.il2(identity)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer2_1(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer2_2(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer2_3(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x2 = x\n",
    "        \n",
    "        # Layer 3\n",
    "        identity = x\n",
    "        x = self.layer3_0(x)\n",
    "        identity = self.il3(identity)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer3_1(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer3_2(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer3_3(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer3_4(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer3_5(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x3 = x\n",
    "        \n",
    "        # Layer 4\n",
    "        identity = x\n",
    "        x = self.layer4_0(x)\n",
    "        identity = self.il4(identity)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer4_1(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.layer4_2(x)\n",
    "        x = x + identity\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        # Decoder Path\n",
    "        x = self.up1(x, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.outconvblock(x)\n",
    "        x = self.outconv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Res_Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=False\n",
    "#for param in model.in_conv.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    #param.requires_grad=True\n",
    "for param in model.up1.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=True\n",
    "for param in model.up2.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=True\n",
    "for param in model.up3.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=True\n",
    "for param in model.outconv.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=True\n",
    "for param in model.outconvblock.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():    # set requires_grad true for in_conv, outconv, outconvblock, up1, up2, up3\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Loss Function (Perceptual Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGPerceptualLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = torchvision.models.vgg19(pretrained=True, progress=False)\n",
    "        features = model.features\n",
    "        self.relu2_2 = nn.Sequential()\n",
    "        for i in range(9):\n",
    "            self.relu2_2.add_module(name=\"relu2_2_\"+str(i+1), module=features[i])    \n",
    "        # Setting requires_grad=False to fix the perceptual loss model parameters \n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out_relu2_2 = self.relu2_2(x)\n",
    "        return out_relu2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGLoss = VGGPerceptualLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerceptualLoss(x, y):\n",
    "    \n",
    "    x_features = VGGLoss(x)\n",
    "    y_features = VGGLoss(y)\n",
    "    \n",
    "    # Calculating feature loss\n",
    "    C = y_features.shape[1]\n",
    "    H = y_features.shape[2]\n",
    "    W = y_features.shape[3]\n",
    "    feature_loss = (F.l1_loss(y_features, x_features, reduction='sum') / (C*H*W)) + (F.l1_loss(x, y) / (C*H*W)) # Here assuming square of Euclidean Norm = MSE Loss\n",
    "    return feature_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing checkpoints\n",
    "def save_checkpoint_best(epoch, model):\n",
    "    print(\"Saving best model\")\n",
    "    PATH = \"/workspace/data/Dhruv/pytorch/SuperResolution/BestModel/best_model_\"+str(epoch)+\".pt\"\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, loss):  # Saving model in a way so we can load and start training again\n",
    "    PATH = \"/workspace/data/Dhruv/pytorch/SuperResolution/Models/model_\"+str(epoch)+\".pt\"\n",
    "    print(\"Saving model\")\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss_log = []\n",
    "val_loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#loss = PerceptualLoss used directly in training loop\n",
    "\n",
    "example = iter(train_loader)\n",
    "example_data, example_target = example.next()\n",
    "writer.add_graph(model, example_data.to(device))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model():\n",
    "\n",
    "  least_val_loss = math.inf\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "      \n",
    "      beg_time = time.time() #To calculate time taken for each epoch\n",
    "      \n",
    "      train_loss = 0.0\n",
    "      val_loss = 0.0\n",
    "      \n",
    "      for i, (x, y) in enumerate(train_loader):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          # Will run for 1000 iterations per epoch\n",
    "          optimizer.zero_grad()\n",
    "          # Forward pass\n",
    "          out = model(x)\n",
    "          #Calculating loss\n",
    "          loss = PerceptualLoss(out, y)\n",
    "          # Backward pass\n",
    "          loss.backward()\n",
    "          # Update gradients\n",
    "          optimizer.step()\n",
    "          # Get training loss\n",
    "          train_loss += loss.item()\n",
    "      tr_loss_log.append(train_loss)\n",
    "      \n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "          for i, (x, y) in enumerate(test_loader):\n",
    "              x = x.to(device)\n",
    "              y = y.to(device)\n",
    "              out = model(x)\n",
    "              #Calculating loss\n",
    "              loss = PerceptualLoss(out, y)\n",
    "              # Get validation loss\n",
    "              val_loss += loss.item()\n",
    "          val_loss_log.append(val_loss)\n",
    "      model.train()\n",
    "      \n",
    "      # Saving checkpoints\n",
    "      save_checkpoint(epoch+1, model, optimizer, val_loss)\n",
    "      if(val_loss < least_val_loss):\n",
    "          save_checkpoint_best(epoch+1, model)\n",
    "          least_val_loss = val_loss\n",
    "          \n",
    "      end_time = time.time()\n",
    "      print('Epoch: {:.0f}/{:.0f}, Time: {:.0f}m {:.0f}s, Train_Loss: {:.4f}, Val_loss: {:.4f}'.format(\n",
    "          epoch+1, EPOCHS, (end_time-beg_time)//60, (end_time-beg_time)%60, train_loss, val_loss))\n",
    "      writer.add_scalar('Training_loss', train_loss, epoch*n_iterations+i)\n",
    "      writer.add_scalar('Validation_loss', val_loss, epoch*n_iterations+i)\n",
    "      writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final model\n",
    "PATH = \"/workspace/data/Dhruv/pytorch/SuperResolution/FinalModel/final_trained_model.pt\"\n",
    "print(\"Saving final model\")\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# To load the best model (fill in the best model epoch number)\n",
    "loaded_best_model = SR_UNet(3).to(device)\n",
    "checkpoint = torch.load(\"/workspace/data/Dhruv/pytorch/SuperResolution/BestModel/best_model_74.pt\")\n",
    "loaded_best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_best_model.eval()\n",
    "#model = loaded_best_model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model with desired epoch number\n",
    "loaded_model = Res_Unet().to(device)\n",
    "checkpoint = torch.load(\"/workspace/data/Dhruv/pytorch/SuperResolution/Models/model_1.pt\")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "#model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example = iter(test_loader)\n",
    "example_data, example_target = example.next()\n",
    "plt.imshow(example_data[15].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(example_data.to(device))\n",
    "plt.imshow(out[15].cpu().detach().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_target[15].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs/2_2_L1_Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include data preprocessing, reduce model complexity, reduce learning rate or add decay rate, add dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
